{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyTerrier\n",
    "\n",
    "_DSAIT4050: Information retrieval lecture, TU Delft_\n",
    "\n",
    "**Part 5: Transformers**\n",
    "\n",
    "This notebook introduces PyTerrier _transformers_ (not to be confused with [neural transformer models](<https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)>)). We'll learn about the different types of data frames that PyTerrier uses and how the transformers operate on them.\n",
    "\n",
    "To run everything in this notebook, you'll need [pyterrier-caching](https://pyterrier.readthedocs.io/en/latest/ext/pyterrier-caching/index.html) and [pyspellchecker](https://github.com/barrust/pyspellchecker) installed:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-terrier==0.12.1\n",
      "  Downloading python_terrier-0.12.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pyterrier-caching==0.3.0\n",
      "  Downloading pyterrier_caching-0.3.0-py3-none-any.whl.metadata (961 bytes)\n",
      "Collecting pyspellchecker\n",
      "  Downloading pyspellchecker-0.8.4-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting numpy (from python-terrier==0.12.1)\n",
      "  Using cached numpy-2.4.2-cp312-cp312-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting pandas (from python-terrier==0.12.1)\n",
      "  Downloading pandas-3.0.1-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting more-itertools (from python-terrier==0.12.1)\n",
      "  Using cached more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting tqdm (from python-terrier==0.12.1)\n",
      "  Using cached tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting requests (from python-terrier==0.12.1)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting ir-datasets>=0.3.2 (from python-terrier==0.12.1)\n",
      "  Using cached ir_datasets-0.5.11-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting wget (from python-terrier==0.12.1)\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pyjnius>=1.4.2 (from python-terrier==0.12.1)\n",
      "  Using cached pyjnius-1.7.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting deprecated (from python-terrier==0.12.1)\n",
      "  Using cached deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting scipy (from python-terrier==0.12.1)\n",
      "  Using cached scipy-1.17.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting ir-measures>=0.3.1 (from python-terrier==0.12.1)\n",
      "  Using cached ir_measures-0.4.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting pytrec-eval-terrier>=0.5.3 (from python-terrier==0.12.1)\n",
      "  Using cached pytrec_eval_terrier-0.5.10-cp312-cp312-win_amd64.whl.metadata (1.1 kB)\n",
      "Collecting jinja2 (from python-terrier==0.12.1)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting statsmodels (from python-terrier==0.12.1)\n",
      "  Using cached statsmodels-0.14.6-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting dill (from python-terrier==0.12.1)\n",
      "  Using cached dill-0.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting joblib (from python-terrier==0.12.1)\n",
      "  Using cached joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting chest (from python-terrier==0.12.1)\n",
      "  Downloading chest-0.2.3.tar.gz (9.6 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pyterrier-alpha>=0.9.4 (from pyterrier-caching==0.3.0)\n",
      "  Downloading pyterrier_alpha-0.16.4-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting lz4 (from pyterrier-caching==0.3.0)\n",
      "  Using cached lz4-4.4.5-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting numpy (from python-terrier==0.12.1)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting npids>=0.0.7 (from pyterrier-caching==0.3.0)\n",
      "  Downloading npids-0.1.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting h5py (from pyterrier-caching==0.3.0)\n",
      "  Downloading h5py-3.15.1-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting beautifulsoup4>=4.4.1 (from ir-datasets>=0.3.2->python-terrier==0.12.1)\n",
      "  Using cached beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting inscriptis>=2.2.0 (from ir-datasets>=0.3.2->python-terrier==0.12.1)\n",
      "  Using cached inscriptis-2.7.0-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting lxml>=4.5.2 (from ir-datasets>=0.3.2->python-terrier==0.12.1)\n",
      "  Using cached lxml-6.0.2-cp312-cp312-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting pyyaml>=5.3.1 (from ir-datasets>=0.3.2->python-terrier==0.12.1)\n",
      "  Using cached pyyaml-6.0.3-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting trec-car-tools>=2.5.4 (from ir-datasets>=0.3.2->python-terrier==0.12.1)\n",
      "  Using cached trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\n",
      "Collecting warc3-wet>=0.2.3 (from ir-datasets>=0.3.2->python-terrier==0.12.1)\n",
      "  Using cached warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting warc3-wet-clueweb09>=0.2.5 (from ir-datasets>=0.3.2->python-terrier==0.12.1)\n",
      "  Using cached warc3_wet_clueweb09-0.2.5-py3-none-any.whl\n",
      "Collecting zlib-state>=0.1.3 (from ir-datasets>=0.3.2->python-terrier==0.12.1)\n",
      "  Using cached zlib_state-0.1.10-cp312-cp312-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting ijson>=3.1.3 (from ir-datasets>=0.3.2->python-terrier==0.12.1)\n",
      "  Using cached ijson-3.5.0-cp312-cp312-win_amd64.whl.metadata (24 kB)\n",
      "Collecting unlzw3>=0.2.1 (from ir-datasets>=0.3.2->python-terrier==0.12.1)\n",
      "  Using cached unlzw3-0.2.3-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyarrow>=16.1.0 (from ir-datasets>=0.3.2->python-terrier==0.12.1)\n",
      "  Using cached pyarrow-23.0.1-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "INFO: pip is looking at multiple versions of pyterrier-alpha to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyterrier-alpha>=0.9.4 (from pyterrier-caching==0.3.0)\n",
      "  Downloading pyterrier_alpha-0.16.3-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Downloading pyterrier_alpha-0.16.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading pyterrier_alpha-0.16.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading pyterrier_alpha-0.15.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading pyterrier_alpha-0.14.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading pyterrier_alpha-0.13.1-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading pyterrier_alpha-0.13.0-py3-none-any.whl.metadata (11 kB)\n",
      "INFO: pip is still looking at multiple versions of pyterrier-alpha to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading pyterrier_alpha-0.12.7-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading pyterrier_alpha-0.12.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting colaburl (from pyterrier-alpha>=0.9.4->pyterrier-caching==0.3.0)\n",
      "  Downloading colaburl-0.1.0-py3-none-any.whl.metadata (971 bytes)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->python-terrier==0.12.1)\n",
      "  Using cached charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->python-terrier==0.12.1)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->python-terrier==0.12.1)\n",
      "  Using cached urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->python-terrier==0.12.1)\n",
      "  Using cached certifi-2026.2.25-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: colorama in d:\\yutin\\tud\\year1\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from tqdm->python-terrier==0.12.1) (0.4.6)\n",
      "Collecting heapdict (from chest->python-terrier==0.12.1)\n",
      "  Downloading HeapDict-1.0.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting wrapt<3,>=1.10 (from deprecated->python-terrier==0.12.1)\n",
      "  Using cached wrapt-2.1.1-cp312-cp312-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->python-terrier==0.12.1)\n",
      "  Using cached markupsafe-3.0.3-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\yutin\\tud\\year1\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from pandas->python-terrier==0.12.1) (2.9.0.post0)\n",
      "Collecting tzdata (from pandas->python-terrier==0.12.1)\n",
      "  Using cached tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting patsy>=0.5.6 (from statsmodels->python-terrier==0.12.1)\n",
      "  Using cached patsy-1.0.2-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in d:\\yutin\\tud\\year1\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from statsmodels->python-terrier==0.12.1) (26.0)\n",
      "Collecting soupsieve>=1.6.1 (from beautifulsoup4>=4.4.1->ir-datasets>=0.3.2->python-terrier==0.12.1)\n",
      "  Using cached soupsieve-2.8.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typing-extensions>=4.0.0 (from beautifulsoup4>=4.4.1->ir-datasets>=0.3.2->python-terrier==0.12.1)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting lxml>=4.5.2 (from ir-datasets>=0.3.2->python-terrier==0.12.1)\n",
      "  Using cached lxml-5.4.0-cp312-cp312-win_amd64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in d:\\yutin\\tud\\year1\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->python-terrier==0.12.1) (1.17.0)\n",
      "Collecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir-datasets>=0.3.2->python-terrier==0.12.1)\n",
      "  Using cached cbor-1.0.0-py3-none-any.whl\n",
      "Downloading python_terrier-0.12.1-py3-none-any.whl (147 kB)\n",
      "   ---------------------------------------- 0.0/147.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 147.8/147.8 kB 8.6 MB/s eta 0:00:00\n",
      "Downloading pyterrier_caching-0.3.0-py3-none-any.whl (20 kB)\n",
      "Downloading pyspellchecker-0.8.4-py3-none-any.whl (7.2 MB)\n",
      "   ---------------------------------------- 0.0/7.2 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.1/7.2 MB 35.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.5/7.2 MB 31.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.6/7.2 MB 32.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.9/7.2 MB 34.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.2/7.2 MB 35.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.2/7.2 MB 30.8 MB/s eta 0:00:00\n",
      "Using cached ir_datasets-0.5.11-py3-none-any.whl (866 kB)\n",
      "Using cached ir_measures-0.4.3-py3-none-any.whl (61 kB)\n",
      "Using cached lz4-4.4.5-cp312-cp312-win_amd64.whl (99 kB)\n",
      "Downloading npids-0.1.3-py3-none-any.whl (26 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Using cached pyjnius-1.7.0-cp312-cp312-win_amd64.whl (209 kB)\n",
      "Downloading pyterrier_alpha-0.12.6-py3-none-any.whl (32 kB)\n",
      "Using cached pytrec_eval_terrier-0.5.10-cp312-cp312-win_amd64.whl (58 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached scipy-1.17.1-cp312-cp312-win_amd64.whl (36.5 MB)\n",
      "Using cached tqdm-4.67.3-py3-none-any.whl (78 kB)\n",
      "Using cached deprecated-1.3.1-py2.py3-none-any.whl (11 kB)\n",
      "Using cached dill-0.4.1-py3-none-any.whl (120 kB)\n",
      "Downloading h5py-3.15.1-cp312-cp312-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 1.7/2.9 MB 54.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.1/2.9 MB 22.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.9/2.9 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 18.4 MB/s eta 0:00:00\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Using cached more_itertools-10.8.0-py3-none-any.whl (69 kB)\n",
      "Downloading pandas-3.0.1-cp312-cp312-win_amd64.whl (9.7 MB)\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.7/9.7 MB 23.8 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.3/9.7 MB 24.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.6/9.7 MB 23.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.2/9.7 MB 25.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.7/9.7 MB 26.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.0/9.7 MB 26.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.0/9.7 MB 27.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.7 MB 27.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.7/9.7 MB 25.0 MB/s eta 0:00:00\n",
      "Using cached statsmodels-0.14.6-cp312-cp312-win_amd64.whl (9.5 MB)\n",
      "Using cached beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
      "Using cached certifi-2026.2.25-py3-none-any.whl (153 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached ijson-3.5.0-cp312-cp312-win_amd64.whl (55 kB)\n",
      "Using cached inscriptis-2.7.0-py3-none-any.whl (45 kB)\n",
      "Using cached lxml-5.4.0-cp312-cp312-win_amd64.whl (3.8 MB)\n",
      "Using cached markupsafe-3.0.3-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached patsy-1.0.2-py2.py3-none-any.whl (233 kB)\n",
      "Using cached pyarrow-23.0.1-cp312-cp312-win_amd64.whl (27.6 MB)\n",
      "Using cached pyyaml-6.0.3-cp312-cp312-win_amd64.whl (154 kB)\n",
      "Using cached trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n",
      "Using cached unlzw3-0.2.3-py3-none-any.whl (6.7 kB)\n",
      "Using cached urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Using cached warc3_wet-0.2.5-py3-none-any.whl (18 kB)\n",
      "Using cached wrapt-2.1.1-cp312-cp312-win_amd64.whl (60 kB)\n",
      "Using cached zlib_state-0.1.10-cp312-cp312-win_amd64.whl (12 kB)\n",
      "Downloading colaburl-0.1.0-py3-none-any.whl (5.4 kB)\n",
      "Downloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n",
      "Using cached tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Using cached soupsieve-2.8.3-py3-none-any.whl (37 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Building wheels for collected packages: chest, wget\n",
      "  Building wheel for chest (pyproject.toml): started\n",
      "  Building wheel for chest (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for chest: filename=chest-0.2.3-py3-none-any.whl size=7736 sha256=12ad1381a663d5445b81d93ad0f1996f4ee550c84680e6a5fc09375eff1cb4f5\n",
      "  Stored in directory: c:\\users\\yutin\\appdata\\local\\pip\\cache\\wheels\\02\\7a\\51\\87f06c3bd6e92a74b4a7f4e582a294f2d5a66f947f212576b4\n",
      "  Building wheel for wget (pyproject.toml): started\n",
      "  Building wheel for wget (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9712 sha256=98179a208859b55ad366c9b0300d82f716d5c7694bb43e931e77b87391ce78e2\n",
      "  Stored in directory: c:\\users\\yutin\\appdata\\local\\pip\\cache\\wheels\\01\\46\\3b\\e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
      "Successfully built chest wget\n",
      "Installing collected packages: wget, warc3-wet-clueweb09, warc3-wet, pyjnius, heapdict, cbor, zlib-state, wrapt, urllib3, unlzw3, tzdata, typing-extensions, tqdm, soupsieve, pyyaml, pyspellchecker, pyarrow, numpy, npids, more-itertools, MarkupSafe, lz4, lxml, joblib, ijson, idna, dill, chest, charset_normalizer, certifi, trec-car-tools, scipy, requests, patsy, pandas, jinja2, h5py, deprecated, colaburl, beautifulsoup4, statsmodels, pytrec-eval-terrier, inscriptis, ir-measures, ir-datasets, python-terrier, pyterrier-alpha, pyterrier-caching\n",
      "Successfully installed MarkupSafe-3.0.3 beautifulsoup4-4.14.3 cbor-1.0.0 certifi-2026.2.25 charset_normalizer-3.4.4 chest-0.2.3 colaburl-0.1.0 deprecated-1.3.1 dill-0.4.1 h5py-3.15.1 heapdict-1.0.1 idna-3.11 ijson-3.5.0 inscriptis-2.7.0 ir-datasets-0.5.11 ir-measures-0.4.3 jinja2-3.1.6 joblib-1.5.3 lxml-5.4.0 lz4-4.4.5 more-itertools-10.8.0 npids-0.1.3 numpy-1.26.4 pandas-3.0.1 patsy-1.0.2 pyarrow-23.0.1 pyjnius-1.7.0 pyspellchecker-0.8.4 pyterrier-alpha-0.12.6 pyterrier-caching-0.3.0 python-terrier-0.12.1 pytrec-eval-terrier-0.5.10 pyyaml-6.0.3 requests-2.32.5 scipy-1.17.1 soupsieve-2.8.3 statsmodels-0.14.6 tqdm-4.67.3 trec-car-tools-2.6 typing-extensions-4.15.0 tzdata-2025.3 unlzw3-0.2.3 urllib3-2.6.3 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 wget-3.2 wrapt-2.1.1 zlib-state-0.1.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install python-terrier==0.12.1 pyterrier-caching==0.3.0 pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we'll illustrate the different kinds of transformers and data frames using examples. Note that we're only scratching the surface here, so **make sure to have a look at the [documentation](https://pyterrier.readthedocs.io/)**!\n",
    "\n",
    "We'll use the `nfcorpus` dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pt.get_dataset(\"irds:nfcorpus/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task we'll need an index with blocks (i.e., positional information), so we need to create a new one, setting `blocks=True`. Since memory indexes do not support blocks at the moment, we'll create one on disk:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] If you have a local copy of https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/nfcorpus.tar.gz, you can symlink it here to avoid downloading it again: C:\\Users\\yutin\\.ir_datasets\\downloads\\49c061fbadc52ba4d35d0e42e2d742fd\n",
      "[INFO] [starting] https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/nfcorpus.tar.gz\n",
      "                                                                 \n",
      "\u001b[A                                                                                                 [INFO] [finished] https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/nfcorpus.tar.gz: [00:00] [2.78kB] [?B/s]\n",
      "[WARNING] Download failed: Expected md5 hash to be 49c061fbadc52ba4d35d0e42e2d742fd but got 48181ed27dd301ecfc4fd86e49a29541\n",
      "nfcorpus/test documents:   0%|          | 0/5371 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\yutin\\\\.ir_datasets\\\\nfcorpus\\\\collection.tsv.tmp1'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHashVerificationError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yutin\\TUD\\Year1\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\fileio.py:68\u001b[39m, in \u001b[36mCache.verify\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_streamer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yutin\\TUD\\Year1\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\fileio.py:96\u001b[39m, in \u001b[36mTarExtract.stream\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;129m@contextlib\u001b[39m.contextmanager\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstream\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcontextlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mExitStack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mctxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_streamer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# IMPORTANT: open this file in streaming mode (| in mode). This means that the\u001b[39;49;00m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# content need not be written to disk or be fully read.\u001b[39;49;00m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarf\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mctxt\u001b[49m\u001b[43m.\u001b[49m\u001b[43menter_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr|\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compression\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yutin\\TUD\\Year1\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\download.py:290\u001b[39m, in \u001b[36mDownload.stream\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    291\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yutin\\TUD\\Year1\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\download.py:277\u001b[39m, in \u001b[36mDownload.path\u001b[39m\u001b[34m(self, force)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.mirrors) == \u001b[32m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.mirrors[\u001b[32m0\u001b[39m], LocalDownload):\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m errors[\u001b[32m1\u001b[39m][\u001b[32m1\u001b[39m]\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mAll download sources failed\u001b[39m\u001b[33m'\u001b[39m, errors)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yutin\\TUD\\Year1\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\download.py:267\u001b[39m, in \u001b[36mDownload.path\u001b[39m\u001b[34m(self, force)\u001b[39m\n\u001b[32m    266\u001b[39m stream = util.HashStream(stream, \u001b[38;5;28mself\u001b[39m.expected_md5, algo=\u001b[33m'\u001b[39m\u001b[33mmd5\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m \u001b[43mshutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\shutil.py:203\u001b[39m, in \u001b[36mcopyfileobj\u001b[39m\u001b[34m(fsrc, fdst, length)\u001b[39m\n\u001b[32m    202\u001b[39m fdst_write = fdst.write\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m buf := \u001b[43mfsrc_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    204\u001b[39m     fdst_write(buf)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yutin\\TUD\\Year1\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\hash.py:51\u001b[39m, in \u001b[36mHashStream.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m count == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_verifier\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m count\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yutin\\TUD\\Year1\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\hash.py:32\u001b[39m, in \u001b[36mHashVerifier.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.expected.lower() != h:\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m HashVerificationError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.algo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m hash to be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.expected\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mHashVerificationError\u001b[39m: Expected md5 hash to be 49c061fbadc52ba4d35d0e42e2d742fd but got 48181ed27dd301ecfc4fd86e49a29541",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      3\u001b[39m idx_path = Path.cwd() / \u001b[33m\"\u001b[39m\u001b[33m05_data\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mnfcorpus_index_with_blocks\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[43mpt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mIterDictIndexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43midx_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_corpus_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtitle\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mabstract\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43murl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yutin\\TUD\\Year1\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\pyterrier\\utils.py:207\u001b[39m, in \u001b[36mpre_invocation_decorator.<locals>._decorator_wrapper.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    206\u001b[39m     decorator(fn)\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yutin\\TUD\\Year1\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\pyterrier\\terrier\\index.py:672\u001b[39m, in \u001b[36m_IterDictIndexer_nofifo.index\u001b[39m\u001b[34m(self, it, fields, meta, meta_lengths, threads)\u001b[39m\n\u001b[32m    667\u001b[39m     iter_docs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    669\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    670\u001b[39m \n\u001b[32m    671\u001b[39m     \u001b[38;5;66;03m# we need to prevent collectionIterator from being GCd\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m672\u001b[39m     collectionIterator = FlatJSONDocumentIterator(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_filter_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    673\u001b[39m     javaDocCollection = pt.terrier.J.CollectionFromDocumentIterator(collectionIterator)\n\u001b[32m    674\u001b[39m     \u001b[38;5;66;03m# remove once 5.7 is now the minimum version\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yutin\\TUD\\Year1\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\pyterrier\\terrier\\index.py:596\u001b[39m, in \u001b[36m_BaseIterDictIndexer._filter_iterable\u001b[39m\u001b[34m(self, it, indexed_fields)\u001b[39m\n\u001b[32m    593\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    594\u001b[39m     all_fields = {\u001b[33m'\u001b[39m\u001b[33mdocno\u001b[39m\u001b[33m'\u001b[39m} | \u001b[38;5;28mset\u001b[39m(indexed_fields) | \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m.meta.keys())\n\u001b[32m--> \u001b[39m\u001b[32m596\u001b[39m first_docs, it = \u001b[43mmore_itertools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# peek at the first document and validate it\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(first_docs) > \u001b[32m0\u001b[39m: \u001b[38;5;66;03m# handle empty input\u001b[39;00m\n\u001b[32m    598\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_doc_dict(first_docs[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yutin\\TUD\\Year1\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\more_itertools\\more.py:1232\u001b[39m, in \u001b[36mspy\u001b[39m\u001b[34m(iterable, n)\u001b[39m\n\u001b[32m   1195\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return a 2-tuple with a list containing the first *n* elements of\u001b[39;00m\n\u001b[32m   1196\u001b[39m \u001b[33;03m*iterable*, and an iterator with the same items as *iterable*.\u001b[39;00m\n\u001b[32m   1197\u001b[39m \u001b[33;03mThis allows you to \"look ahead\" at the items in the iterable without\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1229\u001b[39m \n\u001b[32m   1230\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1231\u001b[39m p, q = tee(iterable)\n\u001b[32m-> \u001b[39m\u001b[32m1232\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m, p\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yutin\\TUD\\Year1\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\more_itertools\\recipes.py:133\u001b[39m, in \u001b[36mtake\u001b[39m\u001b[34m(n, iterable)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtake\u001b[39m(n, iterable):\n\u001b[32m    121\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return first *n* items of the *iterable* as a list.\u001b[39;00m\n\u001b[32m    122\u001b[39m \n\u001b[32m    123\u001b[39m \u001b[33;03m        >>> take(3, range(10))\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    131\u001b[39m \n\u001b[32m    132\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yutin\\TUD\\Year1\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\pyterrier\\datasets.py:432\u001b[39m, in \u001b[36mIRDSDataset.get_corpus_iter.<locals>.gen\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgen\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_asdict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# pyterrier uses \"docno\"\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yutin\\TUD\\Year1\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yutin\\TUD\\Year1\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\__init__.py:147\u001b[39m, in \u001b[36mDocstoreSplitter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mit\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yutin\\TUD\\Year1\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\formats\\tsv.py:93\u001b[39m, in \u001b[36mTsvIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     line = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mline_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m     cols = line.rstrip(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m).split(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     95\u001b[39m     num_cols = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.cls._fields)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yutin\\TUD\\Year1\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\formats\\tsv.py:28\u001b[39m, in \u001b[36mFileLineIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     26\u001b[39m         \u001b[38;5;28mself\u001b[39m.stream = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.ctxt.enter_context(\u001b[38;5;28mself\u001b[39m.dlc[\u001b[38;5;28mself\u001b[39m.stream_idx].stream()))\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m         \u001b[38;5;28mself\u001b[39m.stream = io.TextIOWrapper(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mctxt\u001b[49m\u001b[43m.\u001b[49m\u001b[43menter_context\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdlc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     29\u001b[39m line = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pos < \u001b[38;5;28mself\u001b[39m.start:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\contextlib.py:526\u001b[39m, in \u001b[36m_BaseExitStack.enter_context\u001b[39m\u001b[34m(self, cm)\u001b[39m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object does \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    525\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnot support the context manager protocol\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m result = \u001b[43m_enter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[38;5;28mself\u001b[39m._push_cm_exit(cm, _exit)\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yutin\\TUD\\Year1\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\fileio.py:78\u001b[39m, in \u001b[36mCache.stream\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;129m@contextlib\u001b[39m.contextmanager\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstream\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._path.open(\u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yutin\\TUD\\Year1\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\fileio.py:74\u001b[39m, in \u001b[36mCache.verify\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m Path(f.name).exists():\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m         \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\pathlib.py:1342\u001b[39m, in \u001b[36mPath.unlink\u001b[39m\u001b[34m(self, missing_ok)\u001b[39m\n\u001b[32m   1337\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1338\u001b[39m \u001b[33;03mRemove this file or link.\u001b[39;00m\n\u001b[32m   1339\u001b[39m \u001b[33;03mIf the path is a directory, use rmdir() instead.\u001b[39;00m\n\u001b[32m   1340\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1341\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1342\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[32m   1344\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_ok:\n",
      "\u001b[31mPermissionError\u001b[39m: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\yutin\\\\.ir_datasets\\\\nfcorpus\\\\collection.tsv.tmp1'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "idx_path = Path.cwd() / \"05_data\" / \"nfcorpus_index_with_blocks\"\n",
    "pt.index.IterDictIndexer(\n",
    "    str(idx_path),\n",
    "    blocks=True,\n",
    ").index(dataset.get_corpus_iter(), fields=[\"title\", \"abstract\", \"url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format\n",
    "\n",
    "Recall that the queries (topics) of a dataset can be accessed using the `get_topics` method. For this dataset, there are multiple variants; we choose `title`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] If you have a local copy of https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/nfcorpus.tar.gz, you can symlink it here to avoid downloading it again: C:\\IR\\ir_datasets\\downloads\\49c061fbadc52ba4d35d0e42e2d742fd\n",
      "[INFO] [starting] https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/nfcorpus.tar.gz\n",
      "[INFO] [finished] https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/nfcorpus.tar.gz: [00:00] [2.78kB] [?B/s]\n",
      "[WARNING] Download failed: Expected md5 hash to be 49c061fbadc52ba4d35d0e42e2d742fd but got 48181ed27dd301ecfc4fd86e49a29541\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] : 'C:\\\\IR\\\\ir_datasets\\\\nfcorpus\\\\test\\\\queries.titles.tsv.tmp0'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHashVerificationError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\fileio.py:68\u001b[39m, in \u001b[36mCache.verify\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_streamer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\fileio.py:96\u001b[39m, in \u001b[36mTarExtract.stream\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;129m@contextlib\u001b[39m.contextmanager\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstream\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcontextlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mExitStack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mctxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_streamer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# IMPORTANT: open this file in streaming mode (| in mode). This means that the\u001b[39;49;00m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# content need not be written to disk or be fully read.\u001b[39;49;00m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarf\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mctxt\u001b[49m\u001b[43m.\u001b[49m\u001b[43menter_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr|\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compression\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\download.py:290\u001b[39m, in \u001b[36mDownload.stream\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    291\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\download.py:277\u001b[39m, in \u001b[36mDownload.path\u001b[39m\u001b[34m(self, force)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.mirrors) == \u001b[32m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.mirrors[\u001b[32m0\u001b[39m], LocalDownload):\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m errors[\u001b[32m1\u001b[39m][\u001b[32m1\u001b[39m]\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mAll download sources failed\u001b[39m\u001b[33m'\u001b[39m, errors)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\download.py:267\u001b[39m, in \u001b[36mDownload.path\u001b[39m\u001b[34m(self, force)\u001b[39m\n\u001b[32m    266\u001b[39m stream = util.HashStream(stream, \u001b[38;5;28mself\u001b[39m.expected_md5, algo=\u001b[33m'\u001b[39m\u001b[33mmd5\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m \u001b[43mshutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\shutil.py:203\u001b[39m, in \u001b[36mcopyfileobj\u001b[39m\u001b[34m(fsrc, fdst, length)\u001b[39m\n\u001b[32m    202\u001b[39m fdst_write = fdst.write\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m buf := \u001b[43mfsrc_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    204\u001b[39m     fdst_write(buf)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\hash.py:51\u001b[39m, in \u001b[36mHashStream.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m count == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_verifier\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m count\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\hash.py:32\u001b[39m, in \u001b[36mHashVerifier.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.expected.lower() != h:\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m HashVerificationError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.algo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m hash to be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.expected\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mHashVerificationError\u001b[39m: Expected md5 hash to be 49c061fbadc52ba4d35d0e42e2d742fd but got 48181ed27dd301ecfc4fd86e49a29541",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m queries = \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_topics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtitle\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m queries\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\pyterrier\\datasets.py:459\u001b[39m, in \u001b[36mIRDSDataset.get_topics\u001b[39m\u001b[34m(self, variant, tokenise_query)\u001b[39m\n\u001b[32m    457\u001b[39m qcls = ds.queries_cls()\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m variant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m variant \u001b[38;5;129;01min\u001b[39;00m qcls._fields[\u001b[32m1\u001b[39m:], \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._irds_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m only supports the following topic variants \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqcls._fields[\u001b[32m1\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mqueries_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m df.rename(columns={\u001b[33m\"\u001b[39m\u001b[33mquery_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mqid\u001b[39m\u001b[33m\"\u001b[39m}, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# pyterrier uses \"qid\"\u001b[39;00m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m variant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    464\u001b[39m     \u001b[38;5;66;03m# Some datasets have a query field called \"query\". We need to remove it or\u001b[39;00m\n\u001b[32m    465\u001b[39m     \u001b[38;5;66;03m# we'll end up with multiple \"query\" columns, which will cause problems\u001b[39;00m\n\u001b[32m    466\u001b[39m     \u001b[38;5;66;03m# because many components are written assuming no columns have the same name.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:829\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    827\u001b[39m         data = np.asarray(data)\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m         data = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) > \u001b[32m0\u001b[39m:\n\u001b[32m    831\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_dataclass(data[\u001b[32m0\u001b[39m]):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\datasets\\nfcorpus.py:58\u001b[39m, in \u001b[36mZipQueries.queries_iter\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mqueries_iter\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mqs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mqueries_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_queries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01massert\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mqs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# all query IDs should be the same\u001b[39;49;00m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_qtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_idxs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\formats\\tsv.py:93\u001b[39m, in \u001b[36mTsvIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     line = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mline_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m     cols = line.rstrip(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m).split(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     95\u001b[39m     num_cols = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.cls._fields)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\formats\\tsv.py:28\u001b[39m, in \u001b[36mFileLineIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     26\u001b[39m         \u001b[38;5;28mself\u001b[39m.stream = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.ctxt.enter_context(\u001b[38;5;28mself\u001b[39m.dlc[\u001b[38;5;28mself\u001b[39m.stream_idx].stream()))\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m         \u001b[38;5;28mself\u001b[39m.stream = io.TextIOWrapper(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mctxt\u001b[49m\u001b[43m.\u001b[49m\u001b[43menter_context\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdlc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     29\u001b[39m line = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pos < \u001b[38;5;28mself\u001b[39m.start:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\contextlib.py:526\u001b[39m, in \u001b[36m_BaseExitStack.enter_context\u001b[39m\u001b[34m(self, cm)\u001b[39m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object does \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    525\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnot support the context manager protocol\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m result = \u001b[43m_enter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[38;5;28mself\u001b[39m._push_cm_exit(cm, _exit)\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\fileio.py:78\u001b[39m, in \u001b[36mCache.stream\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;129m@contextlib\u001b[39m.contextmanager\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstream\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._path.open(\u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\fileio.py:74\u001b[39m, in \u001b[36mCache.verify\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m Path(f.name).exists():\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m         \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\pathlib.py:1342\u001b[39m, in \u001b[36mPath.unlink\u001b[39m\u001b[34m(self, missing_ok)\u001b[39m\n\u001b[32m   1337\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1338\u001b[39m \u001b[33;03mRemove this file or link.\u001b[39;00m\n\u001b[32m   1339\u001b[39m \u001b[33;03mIf the path is a directory, use rmdir() instead.\u001b[39;00m\n\u001b[32m   1340\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1341\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1342\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[32m   1344\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_ok:\n",
      "\u001b[31mPermissionError\u001b[39m: [WinError 32] : 'C:\\\\IR\\\\ir_datasets\\\\nfcorpus\\\\test\\\\queries.titles.tsv.tmp0'"
     ]
    }
   ],
   "source": [
    "queries = dataset.get_topics(variant=\"title\")\n",
    "queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, PyTerrier represents all data as `pandas.DataFrame` objects.\n",
    "\n",
    "The method above outputs a data frame with two columns, `qid` and `query`. In PyTerrier, data frames of this format are referred to as _data type_ `Q`, and they essentially represent a set of queries, each of which has a unique identifier. In fact, we have already constructed our own `Q` data frames in the scaffolding project.\n",
    "\n",
    "There are some other data types, and we will introduce them throughout the rest of this series. You can find an overview [here](https://pyterrier.readthedocs.io/en/latest/datamodel.html).\n",
    "\n",
    "## Transformers\n",
    "\n",
    "_Transformers_ directly operate on these data frames; in other words, a transformer takes as input a data frame of some type and outputs another data frame (of the same or another type). We'll take a look at several pre-implemented transformers in this notebook.\n",
    "\n",
    "### Retrieval transformers\n",
    "\n",
    "Retrievers are the most common transformers, and we have already used them plenty throughout this introductory series. For example, let's take a BM25 model as before:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "JavaException",
     "evalue": "JVM exception occurred: java.lang.UnsupportedOperationException: No IndexLoaders were supported for indexref c:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\intro-pyterrier\\05_data\\nfcorpus_index_with_blocks; It may be your ref has the wrong location. Alternatively, Terrier is misconfigured - did you import the correct package to deal with this indexref?\njava.lang.UnsupportedOperationException: No IndexLoaders were supported for indexref c:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\intro-pyterrier\\05_data\\nfcorpus_index_with_blocks; It may be your ref has the wrong location. Alternatively, Terrier is misconfigured - did you import the correct package to deal with this indexref?\n\torg.terrier.structures.IndexFactory.of(IndexFactory.java:143)\n\torg.terrier.structures.IndexFactory.of(IndexFactory.java:114)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJavaException\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m index = \u001b[43mpt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mIndexFactory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mof\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43midx_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m bm25 = pt.terrier.Retriever(index, wmodel=\u001b[33m\"\u001b[39m\u001b[33mBM25\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\pyterrier\\utils.py:207\u001b[39m, in \u001b[36mpre_invocation_decorator.<locals>._decorator_wrapper.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    206\u001b[39m     decorator(fn)\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\pyterrier\\terrier\\index_factory.py:112\u001b[39m, in \u001b[36mIndexFactory.of\u001b[39m\u001b[34m(indexlike, memory)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m memory \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(memory, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(memory) > \u001b[32m0\u001b[39m): \u001b[38;5;66;03m#MEMORY CAN BE A LIST?\u001b[39;00m\n\u001b[32m    111\u001b[39m     pt.terrier.J.IndexOnDisk.setIndexLoadingProfileAsRetrieval(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m index = \u001b[43mpt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mterrier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mJ\u001b[49m\u001b[43m.\u001b[49m\u001b[43mIndexFactory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mof\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# noop if memory is False\u001b[39;00m\n\u001b[32m    115\u001b[39m pt.terrier.J.IndexOnDisk.setIndexLoadingProfileAsRetrieval(load_profile)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mjnius/jnius_export_class.pxi:1187\u001b[39m, in \u001b[36mjnius.JavaMultipleMethod.__call__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mjnius/jnius_export_class.pxi:896\u001b[39m, in \u001b[36mjnius.JavaMethod.__call__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mjnius/jnius_export_class.pxi:1062\u001b[39m, in \u001b[36mjnius.JavaMethod.call_staticmethod\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mjnius/jnius_utils.pxi:79\u001b[39m, in \u001b[36mjnius.check_exception\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mJavaException\u001b[39m: JVM exception occurred: java.lang.UnsupportedOperationException: No IndexLoaders were supported for indexref c:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\intro-pyterrier\\05_data\\nfcorpus_index_with_blocks; It may be your ref has the wrong location. Alternatively, Terrier is misconfigured - did you import the correct package to deal with this indexref?\njava.lang.UnsupportedOperationException: No IndexLoaders were supported for indexref c:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\intro-pyterrier\\05_data\\nfcorpus_index_with_blocks; It may be your ref has the wrong location. Alternatively, Terrier is misconfigured - did you import the correct package to deal with this indexref?\n\torg.terrier.structures.IndexFactory.of(IndexFactory.java:143)\n\torg.terrier.structures.IndexFactory.of(IndexFactory.java:114)"
     ]
    }
   ],
   "source": [
    "index = pt.IndexFactory.of(str(idx_path))\n",
    "bm25 = pt.terrier.Retriever(index, wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transformer consumes data of type `Q` and returns data of type `R` (i.e., columns `qid`, `docno`, `score`, `rank`), which corresponds to a ranking. The transformation can be invoked by calling the `transform` method:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25.transform(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that our result is actually a superset of `R` (we have an additional column, `query`). In general, data frames may have more columns than a specific transformer requires, but they can still be used.\n",
    "\n",
    "Alternatively, the transformer can be called directly, as we have done so far, which gives the same result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, transformers implement the `search` method, which processes a single query:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25.search(\"what is the meaning of life\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query rewriting transformers\n",
    "\n",
    "You have already experimented with query rewriting in the scaffolding project. PyTerrier implements several transformers that rewrite queries.\n",
    "\n",
    "The simplest one is the _sequential dependence model_:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdm = pt.rewrite.SequentialDependence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDM requires positional information in the index (that's why we needed to set a flag during indexing). More information about SDM can be found [here](https://pyterrier.readthedocs.io/en/latest/rewrite.html#sequentialdependence).\n",
    "\n",
    "It operates solely on the queries themselves; in other words, both input and output are data frames of type `Q`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'queries' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m sdm(\u001b[43mqueries\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'queries' is not defined"
     ]
    }
   ],
   "source": [
    "sdm(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the `query` column contains the new (rewritten) queries, while the original queries are retained in the `query_0` column.\n",
    "\n",
    "#### Query expansion\n",
    "\n",
    "_Query expansion_ differs from standard query rewriting in that it operates on queries **and** corresponding relevant documents (these need to be retrieved based on the original queries prior to the expansion). This is also known as _pseudo relevance feedback_ (PRF). A popular PRF model is _RM3_:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm3 = pt.rewrite.RM3(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since RM3 requires a set of documents for each query, its input type needs to be `R`. Consequently, we can use the result of our retriever as an input for the PRF model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm3(bm25(queries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "You probably noticed that the transformers we've seen so far are mostly designed to work in sequence; for example, reformulating queries alone is pointless without an actual retrieval step afterwards.\n",
    "\n",
    "This is where _pipelines_ come into play. PyTerrier implements the `>>` operator to build sequences of transformers. Let's build a simple pipeline that applies SDM and then retrieves documents using BM25:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_sdm = sdm >> bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this pipeline like any other transformer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_sdm(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare SDM and RM3 in terms of performance.\n",
    "\n",
    "First, we create a pipeline for RM3:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_rm3 = bm25 >> rm3 >> bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run an experiment to evaluate and compare both of these pipelines. We'll also include standalone BM25:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier.measures import MAP, nDCG\n",
    "\n",
    "pt.Experiment(\n",
    "    [bm25, pl_sdm, pl_rm3],\n",
    "    queries,\n",
    "    dataset.get_qrels(),\n",
    "    names=[\"BM25\", \"SDM >> BM25\", \"BM25 >> RM3 >> BM25\"],\n",
    "    eval_metrics=[MAP, nDCG @ 10],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caching\n",
    "\n",
    "Caching the outputs of a transformer can be useful when it is part of a pipeline that is executed multiple times. PyTerrier supports caching via a plugin, `pyterrier-caching`, which we have already installed above.\n",
    "\n",
    "Let's time our BM25 retriever without caching first:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit bm25(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a cached version of this retriever using `RetrieverCache`. The results are cached in a directory of our choosing (`bm25_cache`):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier_caching import RetrieverCache\n",
    "\n",
    "bm25_cached = RetrieverCache(Path.cwd() / \"05_data\" / \"bm25_cache\", bm25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the latency of our cached retriever with the uncached version:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit bm25_cached(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overview of the available caches can be found in the [documentation](https://pyterrier.readthedocs.io/en/latest/ext/pyterrier-caching/index.html).\n",
    "\n",
    "**Important**: When you use caching, make sure to clear the cache when you make changes to the transformers you cached. Otherwise, you might get unexpected results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operators\n",
    "\n",
    "There are a number of _operators_ that can be applied to transformers within pipelines. We've already seen the `>>` operator. Here, we'll look at a few more selected operators. You can find the complete list [here](https://pyterrier.readthedocs.io/en/latest/operators.html).\n",
    "\n",
    "#### Rank cutoff\n",
    "\n",
    "The `%` operator limits how many documents per query are kept (the lowest-scoring ones are removed). For example, we may want to consider only a single document for RM3:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_rm3_1doc = (bm25 % 1) >> rm3 >> bm25\n",
    "\n",
    "pt.Experiment(\n",
    "    [pl_rm3, pl_rm3_1doc],\n",
    "    queries,\n",
    "    dataset.get_qrels(),\n",
    "    names=[\"RM3\", \"RM3 (1 document)\"],\n",
    "    eval_metrics=[MAP, nDCG @ 10],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining rankings\n",
    "\n",
    "The `+` and `*` operators can be used to linearly combine two transformers that output rankings (data type `R`). For example, we can use two different retrievers and combine them as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = pt.terrier.Retriever(index, wmodel=\"TF_IDF\")\n",
    "\n",
    "pt.Experiment(\n",
    "    [tf_idf, bm25, 2 * tf_idf + bm25],\n",
    "    queries,\n",
    "    dataset.get_qrels(),\n",
    "    names=[\"TF-IDF\", \"BM25\", \"2 * TF-IDF + BM25\"],\n",
    "    eval_metrics=[MAP, nDCG @ 10],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the operations are applied to the scores computed by the retrievers. If a document is missing for one of the retrievers, a score of `0` is used.\n",
    "\n",
    "### Compiling pipelines\n",
    "\n",
    "Pipelines can be compiled. The compilation may improve the efficiency for certain operations. For example, consider the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = bm25 % 3\n",
    "pl_compiled = pl.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's time them both:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit pl(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit pl_compiled(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom transformers\n",
    "\n",
    "PyTerrier makes it easy for you to implement your own custom transformers. In fact, we've used a custom query transformer under the hood for the scaffolding project.\n",
    "\n",
    "### `apply` functions\n",
    "\n",
    "[`pyterrier.apply`](https://pyterrier.readthedocs.io/en/latest/apply.html) allows for applying a custom function to each row of a data frame. There are many `apply` functions, each of which focuses on different data types. An overview can be found [here](https://pyterrier.readthedocs.io/en/latest/apply.html#module-pyterrier.apply).\n",
    "\n",
    "Let's implement one that reformulates the query to sound a bit nicer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_nicely = pt.apply.query(\n",
    "    lambda row: \"please find some information about \" + row[\"query\"]\n",
    ")\n",
    "ask_nicely(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extending `pyterrier.Transformer`\n",
    "\n",
    "More complex transformers can be implemented by extending the base class directly.\n",
    "\n",
    "Here, we implement a transformer that naively corrects supposed spelling mistakes using a spell checking library. In order to do this, we only need to implement the `transform` method. We adapt the behavior of the other query rewriters and retain the original formulation in the `query_0` column:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "\n",
    "class CorrectQuerySpelling(pt.Transformer):\n",
    "    def __init__(self):\n",
    "        self.spellchecker = SpellChecker()\n",
    "        super().__init__()\n",
    "\n",
    "    def _correct_spelling(self, query: str) -> str:\n",
    "        result = []\n",
    "        for word in query.split(\" \"):\n",
    "            if len(self.spellchecker.unknown([word])) > 0:\n",
    "                result.append(self.spellchecker.correction(word) or word)\n",
    "            else:\n",
    "                result.append(word)\n",
    "        return \" \".join(result)\n",
    "\n",
    "    def transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df_new = df.copy()\n",
    "        df_new[\"query_0\"] = df_new[\"query\"]\n",
    "        df_new[\"query\"] = df_new[\"query_0\"].map(self._correct_spelling)\n",
    "        return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give it a try:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_query_spelling = CorrectQuerySpelling()\n",
    "correct_query_spelling(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "Check out the sections about the [data model](https://pyterrier.readthedocs.io/en/latest/datamodel.html) and [transformers](https://pyterrier.readthedocs.io/en/latest/transformer.html) in the PyTerrier documentation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
