{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyTerrier\n",
    "\n",
    "_DSAIT4050: Information retrieval lecture, TU Delft_\n",
    "\n",
    "**Part 5: Transformers**\n",
    "\n",
    "This notebook introduces PyTerrier _transformers_ (not to be confused with [neural transformer models](<https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)>)). We'll learn about the different types of data frames that PyTerrier uses and how the transformers operate on them.\n",
    "\n",
    "To run everything in this notebook, you'll need [pyterrier-caching](https://pyterrier.readthedocs.io/en/latest/ext/pyterrier-caching/index.html) and [pyspellchecker](https://github.com/barrust/pyspellchecker) installed:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-terrier==0.12.1 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (0.12.1)\n",
      "Requirement already satisfied: pyterrier-caching==0.3.0 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: pyspellchecker in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (0.8.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from python-terrier==0.12.1) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from python-terrier==0.12.1) (3.0.1)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from python-terrier==0.12.1) (10.8.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from python-terrier==0.12.1) (4.67.3)\n",
      "Requirement already satisfied: requests in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from python-terrier==0.12.1) (2.32.5)\n",
      "Requirement already satisfied: ir-datasets>=0.3.2 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from python-terrier==0.12.1) (0.5.11)\n",
      "Requirement already satisfied: wget in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from python-terrier==0.12.1) (3.2)\n",
      "Requirement already satisfied: pyjnius>=1.4.2 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from python-terrier==0.12.1) (1.7.0)\n",
      "Requirement already satisfied: deprecated in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from python-terrier==0.12.1) (1.3.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from python-terrier==0.12.1) (1.17.1)\n",
      "Requirement already satisfied: ir-measures>=0.3.1 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from python-terrier==0.12.1) (0.4.3)\n",
      "Requirement already satisfied: pytrec-eval-terrier>=0.5.3 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from python-terrier==0.12.1) (0.5.10)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from python-terrier==0.12.1) (3.1.6)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from python-terrier==0.12.1) (0.14.6)\n",
      "Requirement already satisfied: dill in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from python-terrier==0.12.1) (0.4.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from python-terrier==0.12.1) (1.5.3)\n",
      "Requirement already satisfied: chest in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from python-terrier==0.12.1) (0.2.3)\n",
      "Requirement already satisfied: pyterrier-alpha>=0.9.4 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from pyterrier-caching==0.3.0) (0.12.6)\n",
      "Requirement already satisfied: lz4 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from pyterrier-caching==0.3.0) (4.4.5)\n",
      "Requirement already satisfied: npids>=0.0.7 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from pyterrier-caching==0.3.0) (0.1.3)\n",
      "Requirement already satisfied: h5py in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from pyterrier-caching==0.3.0) (3.15.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from ir-datasets>=0.3.2->python-terrier==0.12.1) (4.14.3)\n",
      "Requirement already satisfied: inscriptis>=2.2.0 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from ir-datasets>=0.3.2->python-terrier==0.12.1) (2.7.0)\n",
      "Requirement already satisfied: lxml>=4.5.2 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from ir-datasets>=0.3.2->python-terrier==0.12.1) (5.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from ir-datasets>=0.3.2->python-terrier==0.12.1) (6.0.3)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from ir-datasets>=0.3.2->python-terrier==0.12.1) (2.6)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from ir-datasets>=0.3.2->python-terrier==0.12.1) (0.2.5)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from ir-datasets>=0.3.2->python-terrier==0.12.1) (0.2.5)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from ir-datasets>=0.3.2->python-terrier==0.12.1) (0.1.10)\n",
      "Requirement already satisfied: ijson>=3.1.3 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from ir-datasets>=0.3.2->python-terrier==0.12.1) (3.5.0)\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from ir-datasets>=0.3.2->python-terrier==0.12.1) (0.2.3)\n",
      "Requirement already satisfied: pyarrow>=16.1.0 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from ir-datasets>=0.3.2->python-terrier==0.12.1) (23.0.1)\n",
      "Requirement already satisfied: colaburl in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from pyterrier-alpha>=0.9.4->pyterrier-caching==0.3.0) (0.1.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from requests->python-terrier==0.12.1) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from requests->python-terrier==0.12.1) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from requests->python-terrier==0.12.1) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from requests->python-terrier==0.12.1) (2026.2.25)\n",
      "Requirement already satisfied: colorama in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from tqdm->python-terrier==0.12.1) (0.4.6)\n",
      "Requirement already satisfied: heapdict in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from chest->python-terrier==0.12.1) (1.0.1)\n",
      "Requirement already satisfied: wrapt<3,>=1.10 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from deprecated->python-terrier==0.12.1) (2.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from jinja2->python-terrier==0.12.1) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from pandas->python-terrier==0.12.1) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from pandas->python-terrier==0.12.1) (2025.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from statsmodels->python-terrier==0.12.1) (1.0.2)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from statsmodels->python-terrier==0.12.1) (26.0)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from beautifulsoup4>=4.4.1->ir-datasets>=0.3.2->python-terrier==0.12.1) (2.8.3)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from beautifulsoup4>=4.4.1->ir-datasets>=0.3.2->python-terrier==0.12.1) (4.15.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->python-terrier==0.12.1) (1.17.0)\n",
      "Requirement already satisfied: cbor>=1.0.0 in c:\\users\\yutin\\tud\\dsait4050 information retrieval\\ms-information-retrieval\\venv\\lib\\site-packages (from trec-car-tools>=2.5.4->ir-datasets>=0.3.2->python-terrier==0.12.1) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install python-terrier==0.12.1 pyterrier-caching==0.3.0 pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we'll illustrate the different kinds of transformers and data frames using examples. Note that we're only scratching the surface here, so **make sure to have a look at the [documentation](https://pyterrier.readthedocs.io/)**!\n",
    "\n",
    "We'll use the `nfcorpus` dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pt.get_dataset(\"irds:nfcorpus/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task we'll need an index with blocks (i.e., positional information), so we need to create a new one, setting `blocks=True`. Since memory indexes do not support blocks at the moment, we'll create one on disk:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] If you have a local copy of https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/nfcorpus.tar.gz, you can symlink it here to avoid downloading it again: C:\\IR\\ir_datasets\\downloads\\49c061fbadc52ba4d35d0e42e2d742fd\n",
      "[INFO] [starting] https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/nfcorpus.tar.gz\n",
      "                                                                 \n",
      "\u001b[A                                                                                                 [INFO] [finished] https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/nfcorpus.tar.gz: [00:00] [2.78kB] [?B/s]\n",
      "[WARNING] Download failed: Expected md5 hash to be 49c061fbadc52ba4d35d0e42e2d742fd but got 48181ed27dd301ecfc4fd86e49a29541\n",
      "nfcorpus/test documents:   0%|          | 0/5371 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] 另一个程序正在使用此文件，进程无法访问。: 'C:\\\\IR\\\\ir_datasets\\\\nfcorpus\\\\collection.tsv.tmp1'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHashVerificationError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\fileio.py:68\u001b[39m, in \u001b[36mCache.verify\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_streamer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\fileio.py:96\u001b[39m, in \u001b[36mTarExtract.stream\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;129m@contextlib\u001b[39m.contextmanager\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstream\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcontextlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mExitStack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mctxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_streamer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# IMPORTANT: open this file in streaming mode (| in mode). This means that the\u001b[39;49;00m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# content need not be written to disk or be fully read.\u001b[39;49;00m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarf\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mctxt\u001b[49m\u001b[43m.\u001b[49m\u001b[43menter_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr|\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compression\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\download.py:290\u001b[39m, in \u001b[36mDownload.stream\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    291\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\download.py:277\u001b[39m, in \u001b[36mDownload.path\u001b[39m\u001b[34m(self, force)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.mirrors) == \u001b[32m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.mirrors[\u001b[32m0\u001b[39m], LocalDownload):\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m errors[\u001b[32m1\u001b[39m][\u001b[32m1\u001b[39m]\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mAll download sources failed\u001b[39m\u001b[33m'\u001b[39m, errors)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\download.py:267\u001b[39m, in \u001b[36mDownload.path\u001b[39m\u001b[34m(self, force)\u001b[39m\n\u001b[32m    266\u001b[39m stream = util.HashStream(stream, \u001b[38;5;28mself\u001b[39m.expected_md5, algo=\u001b[33m'\u001b[39m\u001b[33mmd5\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m \u001b[43mshutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\shutil.py:203\u001b[39m, in \u001b[36mcopyfileobj\u001b[39m\u001b[34m(fsrc, fdst, length)\u001b[39m\n\u001b[32m    202\u001b[39m fdst_write = fdst.write\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m buf := \u001b[43mfsrc_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    204\u001b[39m     fdst_write(buf)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\hash.py:51\u001b[39m, in \u001b[36mHashStream.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m count == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_verifier\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m count\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\hash.py:32\u001b[39m, in \u001b[36mHashVerifier.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.expected.lower() != h:\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m HashVerificationError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.algo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m hash to be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.expected\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mHashVerificationError\u001b[39m: Expected md5 hash to be 49c061fbadc52ba4d35d0e42e2d742fd but got 48181ed27dd301ecfc4fd86e49a29541",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      3\u001b[39m idx_path = Path.cwd() / \u001b[33m\"\u001b[39m\u001b[33m05_data\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mnfcorpus_index_with_blocks\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[43mpt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mIterDictIndexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43midx_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_corpus_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtitle\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mabstract\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43murl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\pyterrier\\utils.py:207\u001b[39m, in \u001b[36mpre_invocation_decorator.<locals>._decorator_wrapper.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    206\u001b[39m     decorator(fn)\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\pyterrier\\terrier\\index.py:672\u001b[39m, in \u001b[36m_IterDictIndexer_nofifo.index\u001b[39m\u001b[34m(self, it, fields, meta, meta_lengths, threads)\u001b[39m\n\u001b[32m    667\u001b[39m     iter_docs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    669\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    670\u001b[39m \n\u001b[32m    671\u001b[39m     \u001b[38;5;66;03m# we need to prevent collectionIterator from being GCd\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m672\u001b[39m     collectionIterator = FlatJSONDocumentIterator(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_filter_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    673\u001b[39m     javaDocCollection = pt.terrier.J.CollectionFromDocumentIterator(collectionIterator)\n\u001b[32m    674\u001b[39m     \u001b[38;5;66;03m# remove once 5.7 is now the minimum version\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\pyterrier\\terrier\\index.py:596\u001b[39m, in \u001b[36m_BaseIterDictIndexer._filter_iterable\u001b[39m\u001b[34m(self, it, indexed_fields)\u001b[39m\n\u001b[32m    593\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    594\u001b[39m     all_fields = {\u001b[33m'\u001b[39m\u001b[33mdocno\u001b[39m\u001b[33m'\u001b[39m} | \u001b[38;5;28mset\u001b[39m(indexed_fields) | \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m.meta.keys())\n\u001b[32m--> \u001b[39m\u001b[32m596\u001b[39m first_docs, it = \u001b[43mmore_itertools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# peek at the first document and validate it\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(first_docs) > \u001b[32m0\u001b[39m: \u001b[38;5;66;03m# handle empty input\u001b[39;00m\n\u001b[32m    598\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_doc_dict(first_docs[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\more_itertools\\more.py:1232\u001b[39m, in \u001b[36mspy\u001b[39m\u001b[34m(iterable, n)\u001b[39m\n\u001b[32m   1195\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return a 2-tuple with a list containing the first *n* elements of\u001b[39;00m\n\u001b[32m   1196\u001b[39m \u001b[33;03m*iterable*, and an iterator with the same items as *iterable*.\u001b[39;00m\n\u001b[32m   1197\u001b[39m \u001b[33;03mThis allows you to \"look ahead\" at the items in the iterable without\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1229\u001b[39m \n\u001b[32m   1230\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1231\u001b[39m p, q = tee(iterable)\n\u001b[32m-> \u001b[39m\u001b[32m1232\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m, p\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\more_itertools\\recipes.py:133\u001b[39m, in \u001b[36mtake\u001b[39m\u001b[34m(n, iterable)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtake\u001b[39m(n, iterable):\n\u001b[32m    121\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return first *n* items of the *iterable* as a list.\u001b[39;00m\n\u001b[32m    122\u001b[39m \n\u001b[32m    123\u001b[39m \u001b[33;03m        >>> take(3, range(10))\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    131\u001b[39m \n\u001b[32m    132\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\pyterrier\\datasets.py:432\u001b[39m, in \u001b[36mIRDSDataset.get_corpus_iter.<locals>.gen\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgen\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_asdict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# pyterrier uses \"docno\"\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\__init__.py:147\u001b[39m, in \u001b[36mDocstoreSplitter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mit\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\formats\\tsv.py:93\u001b[39m, in \u001b[36mTsvIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     line = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mline_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m     cols = line.rstrip(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m).split(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     95\u001b[39m     num_cols = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.cls._fields)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\formats\\tsv.py:28\u001b[39m, in \u001b[36mFileLineIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     26\u001b[39m         \u001b[38;5;28mself\u001b[39m.stream = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.ctxt.enter_context(\u001b[38;5;28mself\u001b[39m.dlc[\u001b[38;5;28mself\u001b[39m.stream_idx].stream()))\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m         \u001b[38;5;28mself\u001b[39m.stream = io.TextIOWrapper(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mctxt\u001b[49m\u001b[43m.\u001b[49m\u001b[43menter_context\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdlc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     29\u001b[39m line = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pos < \u001b[38;5;28mself\u001b[39m.start:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\contextlib.py:526\u001b[39m, in \u001b[36m_BaseExitStack.enter_context\u001b[39m\u001b[34m(self, cm)\u001b[39m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object does \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    525\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnot support the context manager protocol\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m result = \u001b[43m_enter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[38;5;28mself\u001b[39m._push_cm_exit(cm, _exit)\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\fileio.py:78\u001b[39m, in \u001b[36mCache.stream\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;129m@contextlib\u001b[39m.contextmanager\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstream\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._path.open(\u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\fileio.py:74\u001b[39m, in \u001b[36mCache.verify\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m Path(f.name).exists():\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m         \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\pathlib.py:1342\u001b[39m, in \u001b[36mPath.unlink\u001b[39m\u001b[34m(self, missing_ok)\u001b[39m\n\u001b[32m   1337\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1338\u001b[39m \u001b[33;03mRemove this file or link.\u001b[39;00m\n\u001b[32m   1339\u001b[39m \u001b[33;03mIf the path is a directory, use rmdir() instead.\u001b[39;00m\n\u001b[32m   1340\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1341\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1342\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[32m   1344\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_ok:\n",
      "\u001b[31mPermissionError\u001b[39m: [WinError 32] 另一个程序正在使用此文件，进程无法访问。: 'C:\\\\IR\\\\ir_datasets\\\\nfcorpus\\\\collection.tsv.tmp1'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "idx_path = Path.cwd() / \"05_data\" / \"nfcorpus_index_with_blocks\"\n",
    "pt.index.IterDictIndexer(\n",
    "    str(idx_path),\n",
    "    blocks=True,\n",
    ").index(dataset.get_corpus_iter(), fields=[\"title\", \"abstract\", \"url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format\n",
    "\n",
    "Recall that the queries (topics) of a dataset can be accessed using the `get_topics` method. For this dataset, there are multiple variants; we choose `title`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] If you have a local copy of https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/nfcorpus.tar.gz, you can symlink it here to avoid downloading it again: C:\\IR\\ir_datasets\\downloads\\49c061fbadc52ba4d35d0e42e2d742fd\n",
      "[INFO] [starting] https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/nfcorpus.tar.gz\n",
      "[INFO] [finished] https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/nfcorpus.tar.gz: [00:00] [2.78kB] [?B/s]\n",
      "[WARNING] Download failed: Expected md5 hash to be 49c061fbadc52ba4d35d0e42e2d742fd but got 48181ed27dd301ecfc4fd86e49a29541\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] 另一个程序正在使用此文件，进程无法访问。: 'C:\\\\IR\\\\ir_datasets\\\\nfcorpus\\\\test\\\\queries.titles.tsv.tmp0'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHashVerificationError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\fileio.py:68\u001b[39m, in \u001b[36mCache.verify\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_streamer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\fileio.py:96\u001b[39m, in \u001b[36mTarExtract.stream\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;129m@contextlib\u001b[39m.contextmanager\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstream\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcontextlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mExitStack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mctxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_streamer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# IMPORTANT: open this file in streaming mode (| in mode). This means that the\u001b[39;49;00m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# content need not be written to disk or be fully read.\u001b[39;49;00m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarf\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mctxt\u001b[49m\u001b[43m.\u001b[49m\u001b[43menter_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr|\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compression\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\download.py:290\u001b[39m, in \u001b[36mDownload.stream\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    291\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\download.py:277\u001b[39m, in \u001b[36mDownload.path\u001b[39m\u001b[34m(self, force)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.mirrors) == \u001b[32m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.mirrors[\u001b[32m0\u001b[39m], LocalDownload):\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m errors[\u001b[32m1\u001b[39m][\u001b[32m1\u001b[39m]\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mAll download sources failed\u001b[39m\u001b[33m'\u001b[39m, errors)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\download.py:267\u001b[39m, in \u001b[36mDownload.path\u001b[39m\u001b[34m(self, force)\u001b[39m\n\u001b[32m    266\u001b[39m stream = util.HashStream(stream, \u001b[38;5;28mself\u001b[39m.expected_md5, algo=\u001b[33m'\u001b[39m\u001b[33mmd5\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m \u001b[43mshutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\shutil.py:203\u001b[39m, in \u001b[36mcopyfileobj\u001b[39m\u001b[34m(fsrc, fdst, length)\u001b[39m\n\u001b[32m    202\u001b[39m fdst_write = fdst.write\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m buf := \u001b[43mfsrc_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    204\u001b[39m     fdst_write(buf)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\hash.py:51\u001b[39m, in \u001b[36mHashStream.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m count == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_verifier\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m count\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\hash.py:32\u001b[39m, in \u001b[36mHashVerifier.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.expected.lower() != h:\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m HashVerificationError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.algo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m hash to be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.expected\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mHashVerificationError\u001b[39m: Expected md5 hash to be 49c061fbadc52ba4d35d0e42e2d742fd but got 48181ed27dd301ecfc4fd86e49a29541",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m queries = \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_topics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtitle\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m queries\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\pyterrier\\datasets.py:459\u001b[39m, in \u001b[36mIRDSDataset.get_topics\u001b[39m\u001b[34m(self, variant, tokenise_query)\u001b[39m\n\u001b[32m    457\u001b[39m qcls = ds.queries_cls()\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m variant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m variant \u001b[38;5;129;01min\u001b[39;00m qcls._fields[\u001b[32m1\u001b[39m:], \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._irds_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m only supports the following topic variants \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqcls._fields[\u001b[32m1\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mqueries_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m df.rename(columns={\u001b[33m\"\u001b[39m\u001b[33mquery_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mqid\u001b[39m\u001b[33m\"\u001b[39m}, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# pyterrier uses \"qid\"\u001b[39;00m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m variant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    464\u001b[39m     \u001b[38;5;66;03m# Some datasets have a query field called \"query\". We need to remove it or\u001b[39;00m\n\u001b[32m    465\u001b[39m     \u001b[38;5;66;03m# we'll end up with multiple \"query\" columns, which will cause problems\u001b[39;00m\n\u001b[32m    466\u001b[39m     \u001b[38;5;66;03m# because many components are written assuming no columns have the same name.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:829\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    827\u001b[39m         data = np.asarray(data)\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m         data = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) > \u001b[32m0\u001b[39m:\n\u001b[32m    831\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_dataclass(data[\u001b[32m0\u001b[39m]):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\datasets\\nfcorpus.py:58\u001b[39m, in \u001b[36mZipQueries.queries_iter\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mqueries_iter\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mqs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mqueries_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_queries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01massert\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mqs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# all query IDs should be the same\u001b[39;49;00m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_qtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_idxs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\formats\\tsv.py:93\u001b[39m, in \u001b[36mTsvIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     line = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mline_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m     cols = line.rstrip(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m).split(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     95\u001b[39m     num_cols = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.cls._fields)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\formats\\tsv.py:28\u001b[39m, in \u001b[36mFileLineIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     26\u001b[39m         \u001b[38;5;28mself\u001b[39m.stream = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.ctxt.enter_context(\u001b[38;5;28mself\u001b[39m.dlc[\u001b[38;5;28mself\u001b[39m.stream_idx].stream()))\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m         \u001b[38;5;28mself\u001b[39m.stream = io.TextIOWrapper(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mctxt\u001b[49m\u001b[43m.\u001b[49m\u001b[43menter_context\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdlc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     29\u001b[39m line = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pos < \u001b[38;5;28mself\u001b[39m.start:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\contextlib.py:526\u001b[39m, in \u001b[36m_BaseExitStack.enter_context\u001b[39m\u001b[34m(self, cm)\u001b[39m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object does \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    525\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnot support the context manager protocol\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m result = \u001b[43m_enter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[38;5;28mself\u001b[39m._push_cm_exit(cm, _exit)\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\fileio.py:78\u001b[39m, in \u001b[36mCache.stream\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;129m@contextlib\u001b[39m.contextmanager\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstream\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._path.open(\u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\ir_datasets\\util\\fileio.py:74\u001b[39m, in \u001b[36mCache.verify\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m Path(f.name).exists():\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m         \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\pathlib.py:1342\u001b[39m, in \u001b[36mPath.unlink\u001b[39m\u001b[34m(self, missing_ok)\u001b[39m\n\u001b[32m   1337\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1338\u001b[39m \u001b[33;03mRemove this file or link.\u001b[39;00m\n\u001b[32m   1339\u001b[39m \u001b[33;03mIf the path is a directory, use rmdir() instead.\u001b[39;00m\n\u001b[32m   1340\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1341\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1342\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[32m   1344\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_ok:\n",
      "\u001b[31mPermissionError\u001b[39m: [WinError 32] 另一个程序正在使用此文件，进程无法访问。: 'C:\\\\IR\\\\ir_datasets\\\\nfcorpus\\\\test\\\\queries.titles.tsv.tmp0'"
     ]
    }
   ],
   "source": [
    "queries = dataset.get_topics(variant=\"title\")\n",
    "queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, PyTerrier represents all data as `pandas.DataFrame` objects.\n",
    "\n",
    "The method above outputs a data frame with two columns, `qid` and `query`. In PyTerrier, data frames of this format are referred to as _data type_ `Q`, and they essentially represent a set of queries, each of which has a unique identifier. In fact, we have already constructed our own `Q` data frames in the scaffolding project.\n",
    "\n",
    "There are some other data types, and we will introduce them throughout the rest of this series. You can find an overview [here](https://pyterrier.readthedocs.io/en/latest/datamodel.html).\n",
    "\n",
    "## Transformers\n",
    "\n",
    "_Transformers_ directly operate on these data frames; in other words, a transformer takes as input a data frame of some type and outputs another data frame (of the same or another type). We'll take a look at several pre-implemented transformers in this notebook.\n",
    "\n",
    "### Retrieval transformers\n",
    "\n",
    "Retrievers are the most common transformers, and we have already used them plenty throughout this introductory series. For example, let's take a BM25 model as before:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "JavaException",
     "evalue": "JVM exception occurred: java.lang.UnsupportedOperationException: No IndexLoaders were supported for indexref c:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\intro-pyterrier\\05_data\\nfcorpus_index_with_blocks; It may be your ref has the wrong location. Alternatively, Terrier is misconfigured - did you import the correct package to deal with this indexref?\njava.lang.UnsupportedOperationException: No IndexLoaders were supported for indexref c:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\intro-pyterrier\\05_data\\nfcorpus_index_with_blocks; It may be your ref has the wrong location. Alternatively, Terrier is misconfigured - did you import the correct package to deal with this indexref?\n\torg.terrier.structures.IndexFactory.of(IndexFactory.java:143)\n\torg.terrier.structures.IndexFactory.of(IndexFactory.java:114)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJavaException\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m index = \u001b[43mpt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mIndexFactory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mof\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43midx_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m bm25 = pt.terrier.Retriever(index, wmodel=\u001b[33m\"\u001b[39m\u001b[33mBM25\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\pyterrier\\utils.py:207\u001b[39m, in \u001b[36mpre_invocation_decorator.<locals>._decorator_wrapper.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    206\u001b[39m     decorator(fn)\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\venv\\Lib\\site-packages\\pyterrier\\terrier\\index_factory.py:112\u001b[39m, in \u001b[36mIndexFactory.of\u001b[39m\u001b[34m(indexlike, memory)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m memory \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(memory, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(memory) > \u001b[32m0\u001b[39m): \u001b[38;5;66;03m#MEMORY CAN BE A LIST?\u001b[39;00m\n\u001b[32m    111\u001b[39m     pt.terrier.J.IndexOnDisk.setIndexLoadingProfileAsRetrieval(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m index = \u001b[43mpt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mterrier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mJ\u001b[49m\u001b[43m.\u001b[49m\u001b[43mIndexFactory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mof\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# noop if memory is False\u001b[39;00m\n\u001b[32m    115\u001b[39m pt.terrier.J.IndexOnDisk.setIndexLoadingProfileAsRetrieval(load_profile)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mjnius/jnius_export_class.pxi:1187\u001b[39m, in \u001b[36mjnius.JavaMultipleMethod.__call__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mjnius/jnius_export_class.pxi:896\u001b[39m, in \u001b[36mjnius.JavaMethod.__call__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mjnius/jnius_export_class.pxi:1062\u001b[39m, in \u001b[36mjnius.JavaMethod.call_staticmethod\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mjnius/jnius_utils.pxi:79\u001b[39m, in \u001b[36mjnius.check_exception\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mJavaException\u001b[39m: JVM exception occurred: java.lang.UnsupportedOperationException: No IndexLoaders were supported for indexref c:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\intro-pyterrier\\05_data\\nfcorpus_index_with_blocks; It may be your ref has the wrong location. Alternatively, Terrier is misconfigured - did you import the correct package to deal with this indexref?\njava.lang.UnsupportedOperationException: No IndexLoaders were supported for indexref c:\\Users\\yutin\\TUD\\DSAIT4050 Information Retrieval\\ms-information-retrieval\\intro-pyterrier\\05_data\\nfcorpus_index_with_blocks; It may be your ref has the wrong location. Alternatively, Terrier is misconfigured - did you import the correct package to deal with this indexref?\n\torg.terrier.structures.IndexFactory.of(IndexFactory.java:143)\n\torg.terrier.structures.IndexFactory.of(IndexFactory.java:114)"
     ]
    }
   ],
   "source": [
    "index = pt.IndexFactory.of(str(idx_path))\n",
    "bm25 = pt.terrier.Retriever(index, wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transformer consumes data of type `Q` and returns data of type `R` (i.e., columns `qid`, `docno`, `score`, `rank`), which corresponds to a ranking. The transformation can be invoked by calling the `transform` method:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25.transform(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that our result is actually a superset of `R` (we have an additional column, `query`). In general, data frames may have more columns than a specific transformer requires, but they can still be used.\n",
    "\n",
    "Alternatively, the transformer can be called directly, as we have done so far, which gives the same result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, transformers implement the `search` method, which processes a single query:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25.search(\"what is the meaning of life\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query rewriting transformers\n",
    "\n",
    "You have already experimented with query rewriting in the scaffolding project. PyTerrier implements several transformers that rewrite queries.\n",
    "\n",
    "The simplest one is the _sequential dependence model_:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdm = pt.rewrite.SequentialDependence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDM requires positional information in the index (that's why we needed to set a flag during indexing). More information about SDM can be found [here](https://pyterrier.readthedocs.io/en/latest/rewrite.html#sequentialdependence).\n",
    "\n",
    "It operates solely on the queries themselves; in other words, both input and output are data frames of type `Q`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdm(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the `query` column contains the new (rewritten) queries, while the original queries are retained in the `query_0` column.\n",
    "\n",
    "#### Query expansion\n",
    "\n",
    "_Query expansion_ differs from standard query rewriting in that it operates on queries **and** corresponding relevant documents (these need to be retrieved based on the original queries prior to the expansion). This is also known as _pseudo relevance feedback_ (PRF). A popular PRF model is _RM3_:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm3 = pt.rewrite.RM3(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since RM3 requires a set of documents for each query, its input type needs to be `R`. Consequently, we can use the result of our retriever as an input for the PRF model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm3(bm25(queries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "You probably noticed that the transformers we've seen so far are mostly designed to work in sequence; for example, reformulating queries alone is pointless without an actual retrieval step afterwards.\n",
    "\n",
    "This is where _pipelines_ come into play. PyTerrier implements the `>>` operator to build sequences of transformers. Let's build a simple pipeline that applies SDM and then retrieves documents using BM25:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_sdm = sdm >> bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this pipeline like any other transformer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_sdm(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare SDM and RM3 in terms of performance.\n",
    "\n",
    "First, we create a pipeline for RM3:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_rm3 = bm25 >> rm3 >> bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run an experiment to evaluate and compare both of these pipelines. We'll also include standalone BM25:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier.measures import MAP, nDCG\n",
    "\n",
    "pt.Experiment(\n",
    "    [bm25, pl_sdm, pl_rm3],\n",
    "    queries,\n",
    "    dataset.get_qrels(),\n",
    "    names=[\"BM25\", \"SDM >> BM25\", \"BM25 >> RM3 >> BM25\"],\n",
    "    eval_metrics=[MAP, nDCG @ 10],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caching\n",
    "\n",
    "Caching the outputs of a transformer can be useful when it is part of a pipeline that is executed multiple times. PyTerrier supports caching via a plugin, `pyterrier-caching`, which we have already installed above.\n",
    "\n",
    "Let's time our BM25 retriever without caching first:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit bm25(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a cached version of this retriever using `RetrieverCache`. The results are cached in a directory of our choosing (`bm25_cache`):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier_caching import RetrieverCache\n",
    "\n",
    "bm25_cached = RetrieverCache(Path.cwd() / \"05_data\" / \"bm25_cache\", bm25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the latency of our cached retriever with the uncached version:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit bm25_cached(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overview of the available caches can be found in the [documentation](https://pyterrier.readthedocs.io/en/latest/ext/pyterrier-caching/index.html).\n",
    "\n",
    "**Important**: When you use caching, make sure to clear the cache when you make changes to the transformers you cached. Otherwise, you might get unexpected results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operators\n",
    "\n",
    "There are a number of _operators_ that can be applied to transformers within pipelines. We've already seen the `>>` operator. Here, we'll look at a few more selected operators. You can find the complete list [here](https://pyterrier.readthedocs.io/en/latest/operators.html).\n",
    "\n",
    "#### Rank cutoff\n",
    "\n",
    "The `%` operator limits how many documents per query are kept (the lowest-scoring ones are removed). For example, we may want to consider only a single document for RM3:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_rm3_1doc = (bm25 % 1) >> rm3 >> bm25\n",
    "\n",
    "pt.Experiment(\n",
    "    [pl_rm3, pl_rm3_1doc],\n",
    "    queries,\n",
    "    dataset.get_qrels(),\n",
    "    names=[\"RM3\", \"RM3 (1 document)\"],\n",
    "    eval_metrics=[MAP, nDCG @ 10],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining rankings\n",
    "\n",
    "The `+` and `*` operators can be used to linearly combine two transformers that output rankings (data type `R`). For example, we can use two different retrievers and combine them as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = pt.terrier.Retriever(index, wmodel=\"TF_IDF\")\n",
    "\n",
    "pt.Experiment(\n",
    "    [tf_idf, bm25, 2 * tf_idf + bm25],\n",
    "    queries,\n",
    "    dataset.get_qrels(),\n",
    "    names=[\"TF-IDF\", \"BM25\", \"2 * TF-IDF + BM25\"],\n",
    "    eval_metrics=[MAP, nDCG @ 10],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the operations are applied to the scores computed by the retrievers. If a document is missing for one of the retrievers, a score of `0` is used.\n",
    "\n",
    "### Compiling pipelines\n",
    "\n",
    "Pipelines can be compiled. The compilation may improve the efficiency for certain operations. For example, consider the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = bm25 % 3\n",
    "pl_compiled = pl.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's time them both:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit pl(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit pl_compiled(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom transformers\n",
    "\n",
    "PyTerrier makes it easy for you to implement your own custom transformers. In fact, we've used a custom query transformer under the hood for the scaffolding project.\n",
    "\n",
    "### `apply` functions\n",
    "\n",
    "[`pyterrier.apply`](https://pyterrier.readthedocs.io/en/latest/apply.html) allows for applying a custom function to each row of a data frame. There are many `apply` functions, each of which focuses on different data types. An overview can be found [here](https://pyterrier.readthedocs.io/en/latest/apply.html#module-pyterrier.apply).\n",
    "\n",
    "Let's implement one that reformulates the query to sound a bit nicer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_nicely = pt.apply.query(\n",
    "    lambda row: \"please find some information about \" + row[\"query\"]\n",
    ")\n",
    "ask_nicely(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extending `pyterrier.Transformer`\n",
    "\n",
    "More complex transformers can be implemented by extending the base class directly.\n",
    "\n",
    "Here, we implement a transformer that naively corrects supposed spelling mistakes using a spell checking library. In order to do this, we only need to implement the `transform` method. We adapt the behavior of the other query rewriters and retain the original formulation in the `query_0` column:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "\n",
    "class CorrectQuerySpelling(pt.Transformer):\n",
    "    def __init__(self):\n",
    "        self.spellchecker = SpellChecker()\n",
    "        super().__init__()\n",
    "\n",
    "    def _correct_spelling(self, query: str) -> str:\n",
    "        result = []\n",
    "        for word in query.split(\" \"):\n",
    "            if len(self.spellchecker.unknown([word])) > 0:\n",
    "                result.append(self.spellchecker.correction(word) or word)\n",
    "            else:\n",
    "                result.append(word)\n",
    "        return \" \".join(result)\n",
    "\n",
    "    def transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df_new = df.copy()\n",
    "        df_new[\"query_0\"] = df_new[\"query\"]\n",
    "        df_new[\"query\"] = df_new[\"query_0\"].map(self._correct_spelling)\n",
    "        return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give it a try:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_query_spelling = CorrectQuerySpelling()\n",
    "correct_query_spelling(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "Check out the sections about the [data model](https://pyterrier.readthedocs.io/en/latest/datamodel.html) and [transformers](https://pyterrier.readthedocs.io/en/latest/transformer.html) in the PyTerrier documentation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
